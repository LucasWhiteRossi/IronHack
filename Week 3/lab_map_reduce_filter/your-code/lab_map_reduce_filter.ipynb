{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reduce from functools, numpy and pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun fact: \n",
    "In 2005, the Python's language author Guido van van Rossum expressed his critics about map(), filter(), and reduce(). He advocated agaist those functions, affirming that loops were more legible and easy to handle. The discussion reached a point of excluding reduce from build-in function, isolating reduce into the functools library.\n",
    "\n",
    "Source: https://www.artima.com/weblogs/viewpost.jsp?thread=98196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up some words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Kahlil Gibran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The book could be downloaded via the this [website](https://www.gutenberg.org/ebooks/58585).\n",
    "* Our first step is download the data and open it in our Python environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory location\n",
    "location = '../58585-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file using the open()\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet_string = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, let's divide the string object we just imported based on the space character;\n",
    "* The method that 'divide' the string is called split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe', 'Project', 'Gutenberg', 'EBook', 'of']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = prophet_string.split(\" \")\n",
    "words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prophet_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87749"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prophet_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13637"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you explain the reason why the type of the element has changed and the number of elements decreased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The split method turns a string into a list. In this case, we divide the string by the spaces elements,\n",
    "#which are deleted from our list of elements, justifying the decrease of elements compared to the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET\\n\\n|Almustafa,', 'the{7}', 'chosen', 'and', 'the\\nbeloved,']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = words[568:]\n",
    "words[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The length of all prophet elements is 13.637. If we drop the first 568 elements, we're expecting to create a new one with 13.069 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13069"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET\\n\\n|Almustafa,',\n",
       " 'the{7}',\n",
       " 'chosen',\n",
       " 'and',\n",
       " 'the\\nbeloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dawn',\n",
       " 'unto']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: The string with references removed\n",
    "    \n",
    "    Example:\n",
    "    Input: 'the{7}'\n",
    "    Output: 'the'\n",
    "    '''\n",
    "    # Your code here:\n",
    "    return x.split(\"{\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference('the{7}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference('who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's check where the '{' is inside our string -- the one we have imported fist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13069"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "prophet_reference = list(map(reference, words))\n",
    "\n",
    "len(prophet_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET\\n\\n|Almustafa,',\n",
       " 'the',\n",
       " 'chosen',\n",
       " 'and',\n",
       " 'the\\nbeloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dawn',\n",
       " 'unto']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_reference[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_break(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: A list of strings split on the line break (\\n) character\n",
    "        \n",
    "    Example:\n",
    "    Input: 'the\\nbeloved'\n",
    "    Output: ['the', 'beloved']\n",
    "    '''\n",
    "    return x.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'beloved']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_break('the\\nbeloved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET', '', '|Almustafa']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_break('PROPHET\\n\\n|Almustafa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PROPHET', '', '|Almustafa,'],\n",
       " ['the'],\n",
       " ['chosen'],\n",
       " ['and'],\n",
       " ['the', 'beloved,'],\n",
       " ['who'],\n",
       " ['was'],\n",
       " ['a'],\n",
       " ['dawn'],\n",
       " ['unto'],\n",
       " ['his'],\n",
       " ['own', 'day,'],\n",
       " ['had'],\n",
       " ['waited'],\n",
       " ['twelve'],\n",
       " ['years'],\n",
       " ['in'],\n",
       " ['the'],\n",
       " ['city', 'of'],\n",
       " ['Orphalese'],\n",
       " ['for'],\n",
       " ['his'],\n",
       " ['ship'],\n",
       " ['that'],\n",
       " ['was'],\n",
       " ['to', 'return'],\n",
       " ['and'],\n",
       " ['bear'],\n",
       " ['him'],\n",
       " ['back'],\n",
       " ['to'],\n",
       " ['the'],\n",
       " ['isle'],\n",
       " ['of', 'his'],\n",
       " ['birth.', '', 'And'],\n",
       " ['in'],\n",
       " ['the'],\n",
       " ['twelfth'],\n",
       " ['year,'],\n",
       " ['on'],\n",
       " ['the'],\n",
       " ['seventh', 'day'],\n",
       " ['of'],\n",
       " ['Ielool,'],\n",
       " ['the'],\n",
       " ['month'],\n",
       " ['of'],\n",
       " ['reaping,'],\n",
       " ['he', 'climbed'],\n",
       " ['the'],\n",
       " ['hill'],\n",
       " ['without'],\n",
       " ['the'],\n",
       " ['city'],\n",
       " ['walls', 'and'],\n",
       " ['looked'],\n",
       " ['seaward;'],\n",
       " ['and'],\n",
       " ['he'],\n",
       " ['beheld'],\n",
       " ['his', 'ship'],\n",
       " ['coming'],\n",
       " ['with'],\n",
       " ['the'],\n",
       " ['mist.', '', 'Then'],\n",
       " ['the'],\n",
       " ['gates'],\n",
       " ['of'],\n",
       " ['his'],\n",
       " ['heart'],\n",
       " ['were'],\n",
       " ['flung', 'open,'],\n",
       " ['and'],\n",
       " ['his'],\n",
       " ['joy'],\n",
       " ['flew'],\n",
       " ['far'],\n",
       " ['over'],\n",
       " ['the'],\n",
       " ['sea.', 'And'],\n",
       " ['he'],\n",
       " ['closed'],\n",
       " ['his'],\n",
       " ['eyes'],\n",
       " ['and'],\n",
       " ['prayed'],\n",
       " ['in'],\n",
       " ['the', 'silences'],\n",
       " ['of'],\n",
       " ['his'],\n",
       " ['soul.', '', '*****', '', 'But'],\n",
       " ['as'],\n",
       " ['he'],\n",
       " ['descended'],\n",
       " ['the'],\n",
       " ['hill,'],\n",
       " ['a'],\n",
       " ['sadness', 'came'],\n",
       " ['upon'],\n",
       " ['him,'],\n",
       " ['and'],\n",
       " ['he'],\n",
       " ['thought'],\n",
       " ['in'],\n",
       " ['his', 'heart:', '', 'How'],\n",
       " ['shall'],\n",
       " ['I'],\n",
       " ['go'],\n",
       " ['in'],\n",
       " ['peace'],\n",
       " ['and'],\n",
       " ['without', 'sorrow?'],\n",
       " ['Nay,'],\n",
       " ['not'],\n",
       " ['without'],\n",
       " ['a'],\n",
       " ['wound'],\n",
       " ['in'],\n",
       " ['the', 'spirit'],\n",
       " ['shall'],\n",
       " ['I'],\n",
       " ['leave'],\n",
       " ['this'],\n",
       " ['city.'],\n",
       " [''],\n",
       " ['the'],\n",
       " ['days'],\n",
       " ['of'],\n",
       " ['pain'],\n",
       " ['I'],\n",
       " ['have'],\n",
       " ['spent', 'within'],\n",
       " ['its'],\n",
       " ['walls,'],\n",
       " ['and'],\n",
       " ['long'],\n",
       " ['were'],\n",
       " ['the', 'nights'],\n",
       " ['of'],\n",
       " ['aloneness;'],\n",
       " ['and'],\n",
       " ['who'],\n",
       " ['can'],\n",
       " ['depart', 'from'],\n",
       " ['his'],\n",
       " ['pain'],\n",
       " ['and'],\n",
       " ['his'],\n",
       " ['aloneness'],\n",
       " ['without', 'regret?', '', 'Too'],\n",
       " ['many'],\n",
       " ['fragments'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['spirit'],\n",
       " ['have'],\n",
       " ['I', 'scattered'],\n",
       " ['in'],\n",
       " ['these'],\n",
       " ['streets,'],\n",
       " ['and'],\n",
       " ['too'],\n",
       " ['many', 'are'],\n",
       " ['the'],\n",
       " ['children'],\n",
       " ['of'],\n",
       " ['my'],\n",
       " ['longing'],\n",
       " ['that'],\n",
       " ['walk', 'naked'],\n",
       " ['among'],\n",
       " ['these'],\n",
       " ['hills,'],\n",
       " ['and'],\n",
       " ['I'],\n",
       " ['cannot', 'withdraw'],\n",
       " ['from'],\n",
       " ['them'],\n",
       " ['without'],\n",
       " ['a'],\n",
       " ['burden'],\n",
       " ['and', 'an'],\n",
       " ['ache.', '', 'It'],\n",
       " ['is'],\n",
       " ['not'],\n",
       " ['a'],\n",
       " ['garment'],\n",
       " ['I'],\n",
       " ['cast'],\n",
       " ['off'],\n",
       " ['this', 'day,'],\n",
       " ['but'],\n",
       " ['a'],\n",
       " ['skin'],\n",
       " ['that'],\n",
       " ['I'],\n",
       " ['tear'],\n",
       " ['with'],\n",
       " ['my'],\n",
       " ['own', 'hands.', '', 'Nor'],\n",
       " ['is'],\n",
       " ['it'],\n",
       " ['a'],\n",
       " ['thought'],\n",
       " ['I'],\n",
       " ['leave'],\n",
       " ['behind'],\n",
       " ['me,', 'but'],\n",
       " ['a'],\n",
       " ['heart'],\n",
       " ['made'],\n",
       " ['sweet'],\n",
       " ['with'],\n",
       " ['hunger'],\n",
       " ['and', 'with'],\n",
       " ['thirst.', '', '*****', '', 'Yet'],\n",
       " ['I'],\n",
       " ['cannot'],\n",
       " ['tarry'],\n",
       " ['longer.', '', 'The'],\n",
       " ['sea'],\n",
       " ['that'],\n",
       " ['calls'],\n",
       " ['all'],\n",
       " ['things'],\n",
       " ['unto'],\n",
       " ['her', 'calls'],\n",
       " ['me,'],\n",
       " ['and'],\n",
       " ['I'],\n",
       " ['must'],\n",
       " ['embark.', '', 'For'],\n",
       " ['to'],\n",
       " ['stay,'],\n",
       " ['though'],\n",
       " ['the'],\n",
       " ['hours'],\n",
       " ['burn'],\n",
       " ['in', 'the'],\n",
       " ['night,'],\n",
       " ['is'],\n",
       " ['to'],\n",
       " ['freeze'],\n",
       " ['and'],\n",
       " ['crystallize', 'and'],\n",
       " ['be'],\n",
       " ['bound'],\n",
       " ['in'],\n",
       " ['a'],\n",
       " ['mould.', '', 'Fain'],\n",
       " ['would'],\n",
       " ['I'],\n",
       " ['take'],\n",
       " ['with'],\n",
       " ['me'],\n",
       " ['all'],\n",
       " ['that'],\n",
       " ['is', 'here.'],\n",
       " ['But'],\n",
       " ['how'],\n",
       " ['shall'],\n",
       " ['I?', '', 'A'],\n",
       " ['voice'],\n",
       " ['cannot'],\n",
       " ['carry'],\n",
       " ['the'],\n",
       " ['tongue'],\n",
       " ['and', ''],\n",
       " ['lips'],\n",
       " ['that'],\n",
       " ['gave'],\n",
       " ['it'],\n",
       " ['wings.'],\n",
       " ['Alone', 'must'],\n",
       " ['it'],\n",
       " ['seek'],\n",
       " ['the'],\n",
       " ['ether.', '', 'And'],\n",
       " ['alone'],\n",
       " ['and'],\n",
       " ['without'],\n",
       " ['his'],\n",
       " ['nest'],\n",
       " ['shall'],\n",
       " ['the', 'eagle'],\n",
       " ['fly'],\n",
       " ['across'],\n",
       " ['the'],\n",
       " ['sun.', '', '*****', '', 'Now'],\n",
       " ['when'],\n",
       " ['he'],\n",
       " ['reached'],\n",
       " ['the'],\n",
       " ['foot'],\n",
       " ['of'],\n",
       " ['the', 'hill,'],\n",
       " ['he'],\n",
       " ['turned'],\n",
       " ['again'],\n",
       " ['towards'],\n",
       " ['the'],\n",
       " ['sea,', 'and'],\n",
       " ['he'],\n",
       " ['saw'],\n",
       " ['his'],\n",
       " ['ship'],\n",
       " ['approaching'],\n",
       " ['the', 'harbour,'],\n",
       " ['and'],\n",
       " ['upon'],\n",
       " ['her'],\n",
       " ['prow'],\n",
       " ['the'],\n",
       " ['mariners,', 'the'],\n",
       " ['men'],\n",
       " ['of'],\n",
       " ['his'],\n",
       " ['own'],\n",
       " ['land.', '', 'And'],\n",
       " ['his'],\n",
       " ['soul'],\n",
       " ['cried'],\n",
       " ['out'],\n",
       " ['to'],\n",
       " ['them,'],\n",
       " ['and'],\n",
       " ['he', 'said:', '', 'Sons'],\n",
       " ['of'],\n",
       " ['my'],\n",
       " ['ancient'],\n",
       " ['mother,'],\n",
       " ['you'],\n",
       " ['riders'],\n",
       " ['of', 'the'],\n",
       " ['tides,', '', 'How'],\n",
       " ['often'],\n",
       " ['have'],\n",
       " ['you'],\n",
       " ['sailed'],\n",
       " ['in'],\n",
       " ['my'],\n",
       " ['dreams.', 'And'],\n",
       " ['now'],\n",
       " ['you'],\n",
       " ['come'],\n",
       " ['in'],\n",
       " ['my'],\n",
       " ['awakening,'],\n",
       " ['which', 'is'],\n",
       " ['my'],\n",
       " ['deeper'],\n",
       " ['dream.', '', 'Ready'],\n",
       " ['am'],\n",
       " ['I'],\n",
       " ['to'],\n",
       " ['go,'],\n",
       " ['and'],\n",
       " ['my'],\n",
       " ['eagerness'],\n",
       " ['with', 'sails'],\n",
       " ['full'],\n",
       " ['set'],\n",
       " ['awaits'],\n",
       " ['the'],\n",
       " ['wind.', '', 'Only'],\n",
       " ['another'],\n",
       " ['breath'],\n",
       " ['will'],\n",
       " ['I'],\n",
       " ['breathe'],\n",
       " ['in', 'this'],\n",
       " ['still'],\n",
       " ['air,'],\n",
       " ['only'],\n",
       " ['another'],\n",
       " ['loving'],\n",
       " ['look', 'cast'],\n",
       " ['backward,', '', 'And'],\n",
       " ['then'],\n",
       " ['I'],\n",
       " ['shall'],\n",
       " ['stand'],\n",
       " ['among'],\n",
       " ['you,'],\n",
       " ['a', 'seafarer'],\n",
       " ['among'],\n",
       " ['seafarers.'],\n",
       " [''],\n",
       " ['you,', 'vast'],\n",
       " ['sea,'],\n",
       " ['sleepless'],\n",
       " ['mother,', '', 'Who'],\n",
       " ['alone'],\n",
       " ['are'],\n",
       " ['peace'],\n",
       " ['and'],\n",
       " ['freedom'],\n",
       " ['to'],\n",
       " ['the', 'river'],\n",
       " ['and'],\n",
       " ['the'],\n",
       " ['stream,', '', 'Only'],\n",
       " ['another'],\n",
       " ['winding'],\n",
       " ['will'],\n",
       " ['this'],\n",
       " ['stream', 'make,'],\n",
       " ['only'],\n",
       " ['another'],\n",
       " ['murmur'],\n",
       " ['in'],\n",
       " ['this'],\n",
       " ['glade,', '', 'And'],\n",
       " ['then'],\n",
       " ['shall'],\n",
       " ['I'],\n",
       " ['come'],\n",
       " ['to'],\n",
       " ['you,'],\n",
       " ['a', 'boundless'],\n",
       " ['drop'],\n",
       " ['to'],\n",
       " ['a'],\n",
       " ['boundless'],\n",
       " ['ocean.', '', '*****', '', 'And'],\n",
       " ['as'],\n",
       " ['he'],\n",
       " ['walked'],\n",
       " ['he'],\n",
       " ['saw'],\n",
       " ['from'],\n",
       " ['afar'],\n",
       " ['men', 'and'],\n",
       " ['women'],\n",
       " ['leaving'],\n",
       " ['their'],\n",
       " ['fields'],\n",
       " ['and'],\n",
       " ['their', 'vineyards'],\n",
       " ['and'],\n",
       " ['hastening'],\n",
       " ['towards'],\n",
       " ['the'],\n",
       " ['city', 'gates.', '', 'And'],\n",
       " ['he'],\n",
       " ['heard'],\n",
       " ['their'],\n",
       " ['voices'],\n",
       " ['calling'],\n",
       " ['his', 'name,'],\n",
       " ['and'],\n",
       " ['shouting'],\n",
       " ['from'],\n",
       " ['field'],\n",
       " ['to'],\n",
       " ['field', 'telling'],\n",
       " ['one'],\n",
       " ['another'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['coming'],\n",
       " ['of'],\n",
       " ['his', 'ship.', '', 'And'],\n",
       " ['he'],\n",
       " ['said'],\n",
       " ['to'],\n",
       " ['himself:', '', 'Shall'],\n",
       " ['the'],\n",
       " ['day'],\n",
       " ['of'],\n",
       " ['parting'],\n",
       " ['be'],\n",
       " ['the'],\n",
       " ['day'],\n",
       " ['of', 'gathering?', '', 'And'],\n",
       " ['shall'],\n",
       " ['it'],\n",
       " ['be'],\n",
       " ['said'],\n",
       " ['that'],\n",
       " ['my'],\n",
       " ['eve'],\n",
       " ['was'],\n",
       " ['in', 'truth'],\n",
       " ['my'],\n",
       " ['dawn?', '', 'And'],\n",
       " ['what'],\n",
       " ['shall'],\n",
       " ['I'],\n",
       " ['give'],\n",
       " ['unto'],\n",
       " ['him'],\n",
       " ['who'],\n",
       " ['has', 'left'],\n",
       " ['his'],\n",
       " ['plough'],\n",
       " ['in'],\n",
       " ['midfurrow,'],\n",
       " ['or'],\n",
       " ['to', 'him'],\n",
       " ['who'],\n",
       " ['has'],\n",
       " ['stopped'],\n",
       " ['the'],\n",
       " ['wheel'],\n",
       " ['of'],\n",
       " ['his', 'winepress?'],\n",
       " [''],\n",
       " ['my'],\n",
       " ['heart'],\n",
       " ['become'],\n",
       " ['a', 'tree'],\n",
       " ['heavy-laden'],\n",
       " ['with'],\n",
       " ['fruit'],\n",
       " ['that'],\n",
       " ['I'],\n",
       " ['may', 'gather'],\n",
       " ['and'],\n",
       " ['give'],\n",
       " ['unto'],\n",
       " ['them?', '', 'And'],\n",
       " ['shall'],\n",
       " ['my'],\n",
       " ['desires'],\n",
       " ['flow'],\n",
       " ['like'],\n",
       " ['a', 'fountain'],\n",
       " ['that'],\n",
       " ['I'],\n",
       " ['may'],\n",
       " ['fill'],\n",
       " ['their'],\n",
       " ['cups?', '', 'Am'],\n",
       " ['I'],\n",
       " ['a'],\n",
       " ['harp'],\n",
       " ['that'],\n",
       " ['the'],\n",
       " ['hand'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['mighty', 'may'],\n",
       " ['touch'],\n",
       " ['me,'],\n",
       " ['or'],\n",
       " ['a'],\n",
       " ['flute'],\n",
       " ['that'],\n",
       " ['his'],\n",
       " ['breath', 'may'],\n",
       " ['pass'],\n",
       " ['through'],\n",
       " ['me?', '', 'A'],\n",
       " ['seeker'],\n",
       " ['of'],\n",
       " ['silences'],\n",
       " ['am'],\n",
       " ['I,'],\n",
       " ['and'],\n",
       " ['what', 'treasure'],\n",
       " ['have'],\n",
       " ['I'],\n",
       " ['found'],\n",
       " ['in'],\n",
       " ['silences'],\n",
       " ['that'],\n",
       " ['I', 'may'],\n",
       " ['dispense'],\n",
       " ['with'],\n",
       " ['confidence?', '', 'If'],\n",
       " ['this'],\n",
       " ['is'],\n",
       " ['my'],\n",
       " ['day'],\n",
       " ['of'],\n",
       " ['harvest,'],\n",
       " ['in'],\n",
       " ['what', 'fields'],\n",
       " ['have'],\n",
       " ['I'],\n",
       " ['sowed'],\n",
       " ['the'],\n",
       " ['seed,'],\n",
       " ['and'],\n",
       " ['in', 'what'],\n",
       " ['unremembered'],\n",
       " ['seasons?', '', 'If'],\n",
       " ['this'],\n",
       " ['indeed'],\n",
       " ['be'],\n",
       " ['the'],\n",
       " ['hour'],\n",
       " ['in'],\n",
       " ['which'],\n",
       " ['I', 'lift'],\n",
       " ['up'],\n",
       " ['my'],\n",
       " ['lantern,'],\n",
       " ['it'],\n",
       " ['is'],\n",
       " ['not'],\n",
       " ['my'],\n",
       " ['flame', 'that'],\n",
       " ['shall'],\n",
       " ['burn'],\n",
       " ['therein.', '', 'Empty'],\n",
       " ['and'],\n",
       " ['dark'],\n",
       " ['shall'],\n",
       " ['I'],\n",
       " ['raise'],\n",
       " ['my'],\n",
       " ['lantern,', '', 'And'],\n",
       " ['the'],\n",
       " ['guardian'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['night'],\n",
       " ['shall'],\n",
       " ['fill', 'it'],\n",
       " ['with'],\n",
       " ['oil'],\n",
       " ['and'],\n",
       " ['he'],\n",
       " ['shall'],\n",
       " ['light'],\n",
       " ['it'],\n",
       " ['also.', '', '*****', '', 'These'],\n",
       " ['things'],\n",
       " ['he'],\n",
       " ['said'],\n",
       " ['in'],\n",
       " ['words.'],\n",
       " ['But'],\n",
       " ['much', 'in'],\n",
       " ['his'],\n",
       " ['heart'],\n",
       " ['remained'],\n",
       " ['unsaid.'],\n",
       " ['For'],\n",
       " [''],\n",
       " ['could'],\n",
       " ['not'],\n",
       " ['speak'],\n",
       " ['his'],\n",
       " ['deeper', 'secret.', '', '*****', '', '[Illustration:'],\n",
       " ['0020]', '', 'And'],\n",
       " ['when'],\n",
       " ['he'],\n",
       " ['entered'],\n",
       " ['into'],\n",
       " ['the'],\n",
       " ['city'],\n",
       " ['all', 'the'],\n",
       " ['people'],\n",
       " ['came'],\n",
       " ['to'],\n",
       " ['meet'],\n",
       " ['him,'],\n",
       " ['and'],\n",
       " ['they', 'were'],\n",
       " ['crying'],\n",
       " ['out'],\n",
       " ['to'],\n",
       " ['him'],\n",
       " ['as'],\n",
       " ['with'],\n",
       " ['one', 'voice.', '', 'And'],\n",
       " ['the'],\n",
       " ['elders'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['city'],\n",
       " ['stood'],\n",
       " ['forth', 'and'],\n",
       " ['said:', '', 'Go'],\n",
       " ['not'],\n",
       " ['yet'],\n",
       " ['away'],\n",
       " ['from'],\n",
       " ['us.', '', 'A'],\n",
       " ['noontide'],\n",
       " ['have'],\n",
       " ['you'],\n",
       " ['been'],\n",
       " ['in'],\n",
       " ['our', 'twilight,'],\n",
       " ['and'],\n",
       " ['your'],\n",
       " ['youth'],\n",
       " ['has'],\n",
       " ['given'],\n",
       " ['us', 'dreams'],\n",
       " ['to'],\n",
       " ['dream.', '', 'No'],\n",
       " ['stranger'],\n",
       " ['are'],\n",
       " ['you'],\n",
       " ['among'],\n",
       " ['us,'],\n",
       " ['nor', 'a'],\n",
       " ['guest,'],\n",
       " ['but'],\n",
       " ['our'],\n",
       " ['son'],\n",
       " ['and'],\n",
       " ['our'],\n",
       " ['dearly', 'beloved.', '', 'Suffer'],\n",
       " ['not'],\n",
       " ['yet'],\n",
       " ['our'],\n",
       " ['eyes'],\n",
       " ['to'],\n",
       " ['hunger'],\n",
       " ['for', 'your'],\n",
       " ['face.', '', '*****', '', 'And'],\n",
       " ['the'],\n",
       " ['priests'],\n",
       " ['and'],\n",
       " ['the'],\n",
       " ['priestesses'],\n",
       " ['said', 'unto'],\n",
       " ['him:', '', 'Let'],\n",
       " ['not'],\n",
       " ['the'],\n",
       " ['waves'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['sea'],\n",
       " ['separate'],\n",
       " ['us', 'now,'],\n",
       " ['and'],\n",
       " ['the'],\n",
       " ['years'],\n",
       " ['you'],\n",
       " ['have'],\n",
       " ['spent'],\n",
       " ['in'],\n",
       " ['our', 'midst'],\n",
       " ['become'],\n",
       " ['a'],\n",
       " ['memory.', '', 'You'],\n",
       " ['have'],\n",
       " ['walked'],\n",
       " ['among'],\n",
       " ['us'],\n",
       " ['a'],\n",
       " ['spirit,', ''],\n",
       " ['your'],\n",
       " ['shadow'],\n",
       " ['has'],\n",
       " ['been'],\n",
       " ['a'],\n",
       " ['light', 'upon'],\n",
       " ['our'],\n",
       " ['faces.', '', 'Much'],\n",
       " ['have'],\n",
       " ['we'],\n",
       " ['loved'],\n",
       " ['you.'],\n",
       " ['But'],\n",
       " ['speechless', 'was'],\n",
       " ['our'],\n",
       " ['love,'],\n",
       " ['and'],\n",
       " ['with'],\n",
       " ['veils'],\n",
       " ['has'],\n",
       " ['it'],\n",
       " ['been', 'veiled.', '', 'Yet'],\n",
       " ['now'],\n",
       " ['it'],\n",
       " ['cries'],\n",
       " ['aloud'],\n",
       " ['unto'],\n",
       " ['you,'],\n",
       " ['and', 'would'],\n",
       " ['stand'],\n",
       " ['revealed'],\n",
       " ['before'],\n",
       " ['you.', '', 'And'],\n",
       " ['ever'],\n",
       " ['has'],\n",
       " ['it'],\n",
       " ['been'],\n",
       " ['that'],\n",
       " ['love'],\n",
       " ['knows', 'not'],\n",
       " ['its'],\n",
       " ['own'],\n",
       " ['depth'],\n",
       " ['until'],\n",
       " ['the'],\n",
       " ['hour'],\n",
       " ['of', 'separation.', '', '*****', '', 'And'],\n",
       " ['others'],\n",
       " ['came'],\n",
       " ['also'],\n",
       " ['and'],\n",
       " ['entreated'],\n",
       " ['him.', 'But'],\n",
       " ['he'],\n",
       " ['answered'],\n",
       " ['them'],\n",
       " ['not.'],\n",
       " ['He'],\n",
       " ['only'],\n",
       " ['bent', 'his'],\n",
       " ['head;'],\n",
       " ['and'],\n",
       " ['those'],\n",
       " ['who'],\n",
       " ['stood'],\n",
       " ['near'],\n",
       " ['saw', 'his'],\n",
       " ['tears'],\n",
       " ['falling'],\n",
       " ['upon'],\n",
       " ['his'],\n",
       " ['breast.', '', 'And'],\n",
       " ['he'],\n",
       " ['and'],\n",
       " ['the'],\n",
       " ['people'],\n",
       " ['proceeded'],\n",
       " ['towards', 'the'],\n",
       " ['great'],\n",
       " ['square'],\n",
       " ['before'],\n",
       " ['the'],\n",
       " ['temple.', '', 'And'],\n",
       " ['there'],\n",
       " ['came'],\n",
       " ['out'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['sanctuary'],\n",
       " ['a', 'woman'],\n",
       " ['whose'],\n",
       " ['name'],\n",
       " ['was'],\n",
       " ['Almitra.'],\n",
       " ['And'],\n",
       " ['she', 'was'],\n",
       " ['a'],\n",
       " ['seeress.', '', 'And'],\n",
       " ['he'],\n",
       " ['looked'],\n",
       " ['upon'],\n",
       " ['her'],\n",
       " ['with'],\n",
       " ['exceeding', 'tenderness,'],\n",
       " ['for'],\n",
       " ['it'],\n",
       " ['was'],\n",
       " ['she'],\n",
       " ['who'],\n",
       " ['had'],\n",
       " ['first', 'sought'],\n",
       " ['and'],\n",
       " ['believed'],\n",
       " ['in'],\n",
       " ['him'],\n",
       " ['when'],\n",
       " ['he'],\n",
       " ['had', 'been'],\n",
       " ['but'],\n",
       " ['a'],\n",
       " ['day'],\n",
       " ['in'],\n",
       " ['their'],\n",
       " ['city.'],\n",
       " [''],\n",
       " ['hailed'],\n",
       " ['him,'],\n",
       " ['saying:', '', 'Prophet'],\n",
       " ['of'],\n",
       " ['God,'],\n",
       " ['in'],\n",
       " ['quest'],\n",
       " ['of'],\n",
       " ['the', 'uttermost,'],\n",
       " ['long'],\n",
       " ['have'],\n",
       " ['you'],\n",
       " ['searched'],\n",
       " ['the', 'distances'],\n",
       " ['for'],\n",
       " ['your'],\n",
       " ['ship.', '', 'And'],\n",
       " ['now'],\n",
       " ['your'],\n",
       " ['ship'],\n",
       " ['has'],\n",
       " ['come,'],\n",
       " ['and'],\n",
       " ['you'],\n",
       " ['must', 'needs'],\n",
       " ['go.', '', 'Deep'],\n",
       " ['is'],\n",
       " ['your'],\n",
       " ['longing'],\n",
       " ['for'],\n",
       " ['the'],\n",
       " ['land'],\n",
       " ['of', 'your'],\n",
       " ['memories'],\n",
       " ['and'],\n",
       " ['the'],\n",
       " ['dwelling'],\n",
       " ['place', 'of'],\n",
       " ['your'],\n",
       " ['greater'],\n",
       " ['desires;'],\n",
       " ['and'],\n",
       " ['our'],\n",
       " ['love', 'would'],\n",
       " ['not'],\n",
       " ['bind'],\n",
       " ['you'],\n",
       " ['nor'],\n",
       " ['our'],\n",
       " ['needs'],\n",
       " ['hold', 'you.', '', 'Yet'],\n",
       " ['this'],\n",
       " ['we'],\n",
       " ['ask'],\n",
       " ['ere'],\n",
       " ['you'],\n",
       " ['leave'],\n",
       " ['us,'],\n",
       " ['that', 'you'],\n",
       " ['speak'],\n",
       " ['to'],\n",
       " ['us'],\n",
       " ['and'],\n",
       " ['give'],\n",
       " ['us'],\n",
       " ['of'],\n",
       " ['your', 'truth.', '', 'And'],\n",
       " ['we'],\n",
       " ['will'],\n",
       " ['give'],\n",
       " ['it'],\n",
       " ['unto'],\n",
       " ['our'],\n",
       " ['children,', 'and'],\n",
       " ['they'],\n",
       " ['unto'],\n",
       " ['their'],\n",
       " ['children,'],\n",
       " ['and'],\n",
       " ['it', 'shall'],\n",
       " ['not'],\n",
       " ['perish.', '', 'In'],\n",
       " ['your'],\n",
       " ['aloneness'],\n",
       " ['you'],\n",
       " ['have'],\n",
       " ['watched'],\n",
       " ['with', 'our'],\n",
       " ['days,'],\n",
       " ['and'],\n",
       " ['in'],\n",
       " ['your'],\n",
       " ['wakefulness'],\n",
       " ['you', 'have'],\n",
       " ['listened'],\n",
       " ['to'],\n",
       " ['the'],\n",
       " ['weeping'],\n",
       " ['and'],\n",
       " ['the', 'laughter'],\n",
       " ['of'],\n",
       " ['our'],\n",
       " ['sleep.', '', 'Now'],\n",
       " ['therefore'],\n",
       " ['disclose'],\n",
       " ['us'],\n",
       " ['to'],\n",
       " ['ourselves,', 'and'],\n",
       " ['tell'],\n",
       " ['us'],\n",
       " ['all'],\n",
       " ['that'],\n",
       " ['has'],\n",
       " ['been'],\n",
       " ['shown', 'you'],\n",
       " ['of'],\n",
       " ['that'],\n",
       " ['which'],\n",
       " ['is'],\n",
       " ['between'],\n",
       " ['birth'],\n",
       " ['and', 'death.', '', '*****', '', 'And'],\n",
       " ['he'],\n",
       " ['answered,', '', 'People'],\n",
       " ['of'],\n",
       " ['Orphalese,'],\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested = list(map(line_break, prophet_reference))\n",
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatened = [item for objeto in nested for item in objeto]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: true if the word is not in the specified list and false if the word is in the list\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    if x in word_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14627"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = list(filter(word_filter, flatened))\n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Part 2\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter_case(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: true if the word is not in the specified list and false if the word is in the list\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    if x.lower() in word_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14334"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = list(filter(word_filter_case, flatened))\n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_space(a, b):\n",
    "    '''\n",
    "    Input:Two strings\n",
    "    Output: A single string separated by a space\n",
    "        \n",
    "    Example:\n",
    "    Input: 'John', 'Smith'\n",
    "    Output: 'John Smith'\n",
    "    '''\n",
    "    return a + ' ' + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPHET  |Almustafa, chosen beloved, who was dawn unto his own day, had waited twelve years in city '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = reduce(concat_space, filtered)\n",
    "new_text[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Applying Functions to DataFrames\n",
    "\n",
    "#### Our next step is to use the apply function to a dataframe and transform all cells.\n",
    "\n",
    "To do this, we will load a dataset below and then write a function that will perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "# The dataset below contains information about pollution from PM2.5 particles in Beijing \n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "pm25 = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a function that divides a cell by 24 to produce an hourly figure. Write the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly(x):\n",
    "    '''\n",
    "    Input: A numerical value\n",
    "    Output: The value divided by 24\n",
    "        \n",
    "    Example:\n",
    "    Input: 48\n",
    "    Output: 2.0\n",
    "    '''\n",
    "    return x/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to the columns `Iws`, `Is`, and `Ir`. Store this new dataframe in the variable `pm25_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.540417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Iws   Is   Ir\n",
       "0  0.074583  0.0  0.0\n",
       "1  0.205000  0.0  0.0\n",
       "2  0.279583  0.0  0.0\n",
       "3  0.410000  0.0  0.0\n",
       "4  0.540417  0.0  0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25_hourly = pm25[[\"Iws\", \"Is\", \"Ir\"]].apply(hourly)\n",
    "pm25_hourly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.\n",
    "\n",
    "Write a function that returns the standard deviation of a column divided by the length of a column minus 1. Since we are using pandas, do not use the `len()` function. One alternative is to use `count()`. Also, use the numpy version of standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sd(x):\n",
    "    '''\n",
    "    Input: A Pandas series of values\n",
    "    Output: the standard deviation divided by the number of elements in the series\n",
    "        \n",
    "    Example:\n",
    "    Input: pd.Series([1,2,3,4])\n",
    "    Output: 0.3726779962\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    lenght = x.count()\n",
    "    standardD = np.std(x)\n",
    "    \n",
    "    return standardD/(lenght-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_sampled = pm25_hourly.apply(sample_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iws    4.754929e-05\n",
       "Is     7.229519e-07\n",
       "Ir     1.346183e-06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   #\n",
      "  ##\n",
      " ###\n",
      "####\n"
     ]
    }
   ],
   "source": [
    "def staircase(n):\n",
    "    for i in range(n):\n",
    "        hashes = i+1\n",
    "        spaces = n-hashes\n",
    "        print(' '*spaces+'#'*hashes)\n",
    "        \n",
    "staircase(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "count() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-c60d5d058358>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: count() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "[2,2,4,5,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
